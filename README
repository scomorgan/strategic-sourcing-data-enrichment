<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>README - Matching AIC File Project</title>
</head>
<body>

<h1>Matching - AIC File Project</h1>

<p>This project aims to enhance data quality, automate workflows, and improve accessibility for multiple projects including Suplari Implementation, P Card, and Travel Analytics. The primary objective is to develop a robust, automated matching framework for AIC files that ensures consistent data across platforms, streamlining workflows and enabling accurate reporting and analysis.</p>

<h2>Project Structure</h2>
<ul>
    <li><strong>docs/</strong> - Documentation files including data dictionary, architecture, and analysis notes.</li>
    <li><strong>config/</strong> - Configuration files for database connections, environment settings, and mapping schemas.</li>
    <li><strong>sql/</strong> - SQL scripts categorized into raw data extraction, transformations, aggregations, and matching logic.</li>
    <li><strong>etl/</strong> - ETL pipeline code with modular functions for data normalization, matching, enrichment, and validation.</li>
    <li><strong>scripts/</strong> - Utility scripts for validating matches, checking data quality, and generating reports.</li>
    <li><strong>data_samples/</strong> - Sample data files (sanitized) for testing ETL processes, including raw and processed data.</li>
</ul>

<h2>Getting Started</h2>
<ol>
    <li>Clone the repository.</li>
    <li>Install required packages by running <code>pip install -r requirements.txt</code>.</li>
    <li>Set up database connections by configuring <code>db_connections.yaml</code> in the <code>config/</code> folder.</li>
    <li>Prepare sample data in the <code>data_samples/</code> folder for initial testing.</li>
</ol>

<h2>Running the ETL Pipeline</h2>
<p>The main ETL pipeline is located in <code>etl/main_etl_pipeline.py</code>. You can run the entire ETL process or execute individual modules as needed:</p>
<pre><code>python etl/main_etl_pipeline.py</code></pre>

<h2>Scripts</h2>
<ul>
    <li><strong>validate_matches.py</strong> - Checks matching accuracy and provides metrics on match rates.</li>
    <li><strong>check_data_quality.py</strong> - Runs data quality checks to identify inconsistencies.</li>
    <li><strong>generate_reports.py</strong> - Generates reports on the matching process and progress.</li>
</ul>

<h2>Key Documentation</h2>
<ul>
    <li><strong>data_dictionary.md</strong> - Detailed documentation of tables, fields, and relationships.</li>
    <li><strong>architecture.md</strong> - High-level overview of data architecture and system integration.</li>
    <li><strong>troubleshooting.md</strong> - Common issues and solutions for data and ETL challenges.</li>
</ul>

<h2>Contributing</h2>
<p>For contributions, please adhere to the following guidelines:</p>
<ol>
    <li>Use branches for specific features or modules, and provide descriptive names (e.g., <code>feature/fuzzy_matching</code>).</li>
    <li>Commit regularly with clear messages describing changes made.</li>
    <li>Document any new functions or scripts added to the repository.</li>
</ol>

<h2>Contact</h2>
<p>For any questions or further assistance, please reach out to the project lead, Scott Morgan.</p>

</body>
</html>
